{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7FWtLjb9sON"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk. corpus import stopwords\n",
        "from nltk.stem. wordnet import WordNetLemmatizer\n",
        "from nltk.stem. porter import PorterStemmer\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3Qb9trr920i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d3cab4-9a5b-4a67-f4ed-6ee4d43e6207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu_C67B3-Sk9"
      },
      "outputs": [],
      "source": [
        "text = \"As the sun slowly set behind the majestic mountains, the cool evening breeze carried the sweet fragrance of blooming flowers, while the distant sound of a waterfall echoed through the valley, creating a tranquil atmosphere for the weary travelers to rest and rejuvenate.\"\n",
        "example_sent = \"After the thunderstorm, the mesmerizing rainbow appeared in the sky, casting a colorful reflection on the rippling surface of the lake, as the birds chirped and flew over the treetops.\"\n",
        "sent = \"Under the soft glow of the full moon, the two lovers strolled hand in hand along the deserted beach, listening to the soothing sound of waves gently crashing against the shore, as they shared sweet whispers and stolen kisses, lost in the blissful moment of their eternal love.\"\n",
        "\n",
        "words = [\"Hike\",\"Hiking\", \"Hiked\", \"Hiker\", \"Hikers\", \"Hikes\", \"Hikings\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB1e5orS-rds"
      },
      "outputs": [],
      "source": [
        "ps = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XKf-75fJYHv"
      },
      "source": [
        "# **Sentance Tokenzation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdLmnFdJ-3eu"
      },
      "outputs": [],
      "source": [
        "def sentence_tokenizer(sentance):\n",
        "  return sent_tokenize(sentance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjA7Vtj2JftO"
      },
      "source": [
        "# **Word Tokenzation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOg3wJZOGeup"
      },
      "outputs": [],
      "source": [
        "def word_tokenizer(sentance):\n",
        "  return word_tokenize(sentance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_YNgsJrJh_p"
      },
      "source": [
        "# **Removing Stopwords**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFkxepjgG2I4"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(sentance):\n",
        "  stop_words=set(stopwords.words('english'))\n",
        "  word_tokens = word_tokenize(example_sent)\n",
        "  filtered_sent = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "  filtered_sent = []\n",
        "  for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "      filtered_sent.append(w)\n",
        "\n",
        "  res = \"Word Tokens: {0}, \\nFiltered: {1}.\".format(word_tokens, filtered_sent)\n",
        "  \n",
        "  return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVIsf8JLJnEO"
      },
      "source": [
        "# **Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8-2TMyXAkb3"
      },
      "outputs": [],
      "source": [
        "def stemming(words):\n",
        "  for w in words:\n",
        "    print(w, \" : \", ps.stem(w))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAft_9y1JqA3"
      },
      "source": [
        "# **Lemmatizing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_9KKVlQ_euV"
      },
      "outputs": [],
      "source": [
        "def lemmatizzer(word):\n",
        "  res = \"{0}: {1}\".format(word, lemmatizer.lemmatize(word))\n",
        "  return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG1xV361JuaL"
      },
      "source": [
        "# **POS Tagging**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB8yLdWvCdbI"
      },
      "outputs": [],
      "source": [
        "def pos_tagger(sentance):\n",
        "  tokens = nltk.word_tokenize(sentance)\n",
        "  pos_tagging = nltk.pos_tag(tokens)\n",
        "  return pos_tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh9P7znGCNHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8013d3d7-994b-4752-f525-380b6055bcc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentance Tokenization\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['As the sun slowly set behind the majestic mountains, the cool evening breeze carried the sweet fragrance of blooming flowers, while the distant sound of a waterfall echoed through the valley, creating a tranquil atmosphere for the weary travelers to rest and rejuvenate.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "print(\"Sentance Tokenization\\n\")\n",
        "sentence_tokenizer(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpaKDra6L4xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c859fb23-3bf7-4f5f-8923-5509a85a8b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Tokenization\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['As',\n",
              " 'the',\n",
              " 'sun',\n",
              " 'slowly',\n",
              " 'set',\n",
              " 'behind',\n",
              " 'the',\n",
              " 'majestic',\n",
              " 'mountains',\n",
              " ',',\n",
              " 'the',\n",
              " 'cool',\n",
              " 'evening',\n",
              " 'breeze',\n",
              " 'carried',\n",
              " 'the',\n",
              " 'sweet',\n",
              " 'fragrance',\n",
              " 'of',\n",
              " 'blooming',\n",
              " 'flowers',\n",
              " ',',\n",
              " 'while',\n",
              " 'the',\n",
              " 'distant',\n",
              " 'sound',\n",
              " 'of',\n",
              " 'a',\n",
              " 'waterfall',\n",
              " 'echoed',\n",
              " 'through',\n",
              " 'the',\n",
              " 'valley',\n",
              " ',',\n",
              " 'creating',\n",
              " 'a',\n",
              " 'tranquil',\n",
              " 'atmosphere',\n",
              " 'for',\n",
              " 'the',\n",
              " 'weary',\n",
              " 'travelers',\n",
              " 'to',\n",
              " 'rest',\n",
              " 'and',\n",
              " 'rejuvenate',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "print(\"Word Tokenization\\n\")\n",
        "word_tokenizer(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLarpZ-cL8NF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "57f4807c-e8fc-4e61-b9e7-4033783e4d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing Stopwords\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Word Tokens: ['After', 'the', 'thunderstorm', ',', 'the', 'mesmerizing', 'rainbow', 'appeared', 'in', 'the', 'sky', ',', 'casting', 'a', 'colorful', 'reflection', 'on', 'the', 'rippling', 'surface', 'of', 'the', 'lake', ',', 'as', 'the', 'birds', 'chirped', 'and', 'flew', 'over', 'the', 'treetops', '.'], \\nFiltered: ['After', 'thunderstorm', ',', 'mesmerizing', 'rainbow', 'appeared', 'sky', ',', 'casting', 'colorful', 'reflection', 'rippling', 'surface', 'lake', ',', 'birds', 'chirped', 'flew', 'treetops', '.'].\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "print(\"Removing Stopwords\\n\")\n",
        "remove_stopwords(example_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzb9U5UoMBzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4124929-e7ae-4e2a-df39-0c7b9a019184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming\n",
            "\n",
            "Hike  :  hike\n",
            "Hiking  :  hike\n",
            "Hiked  :  hike\n",
            "Hiker  :  hiker\n",
            "Hikers  :  hiker\n",
            "Hikes  :  hike\n",
            "Hikings  :  hike\n"
          ]
        }
      ],
      "source": [
        "print(\"Stemming\\n\")\n",
        "stemming(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "wADggKsUMItG",
        "outputId": "d9ebb8f6-79e9-4b34-d837-0bfa99353143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatization\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Amorevole: Amorevole'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "print(\"Lemmatization\\n\")\n",
        "lemmatizzer(\"Amorevole\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssitETUmMKJ3",
        "outputId": "da5a131f-0e0b-4dd6-ed8a-34e35569d8d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tagging\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Under', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('soft', 'JJ'),\n",
              " ('glow', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('full', 'JJ'),\n",
              " ('moon', 'NN'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('two', 'CD'),\n",
              " ('lovers', 'NNS'),\n",
              " ('strolled', 'VBD'),\n",
              " ('hand', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('hand', 'NN'),\n",
              " ('along', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('deserted', 'JJ'),\n",
              " ('beach', 'NN'),\n",
              " (',', ','),\n",
              " ('listening', 'VBG'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('soothing', 'VBG'),\n",
              " ('sound', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('waves', 'NNS'),\n",
              " ('gently', 'RB'),\n",
              " ('crashing', 'VBG'),\n",
              " ('against', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('shore', 'NN'),\n",
              " (',', ','),\n",
              " ('as', 'IN'),\n",
              " ('they', 'PRP'),\n",
              " ('shared', 'VBD'),\n",
              " ('sweet', 'JJ'),\n",
              " ('whispers', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('stolen', 'VBN'),\n",
              " ('kisses', 'NNS'),\n",
              " (',', ','),\n",
              " ('lost', 'VBN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('blissful', 'JJ'),\n",
              " ('moment', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('their', 'PRP$'),\n",
              " ('eternal', 'JJ'),\n",
              " ('love', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "print(\"POS Tagging\\n\")\n",
        "pos_tagger(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF-IDF**"
      ],
      "metadata": {
        "id": "pX3xPw6NHMoW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irTMHyjzvJNW"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "def calculate_tf_idf(document, corpus):\n",
        "    tf_idf = {}\n",
        "    word_counts = Counter(document.split())\n",
        "    total_documents = len(corpus)\n",
        "\n",
        "    for word, count in word_counts.items():\n",
        "        # Calculate term frequency (tf)\n",
        "        tf = count / len(document.split())\n",
        "\n",
        "        # Calculate inverse document frequency (idf)\n",
        "        doc_count = sum([1 for doc in corpus if word in doc])\n",
        "        if doc_count == 0:\n",
        "            idf = 0\n",
        "        else:\n",
        "            idf = math.log(total_documents / doc_count)\n",
        "\n",
        "        # Calculate tf-idf\n",
        "        tf_idf[word] = tf * idf\n",
        "\n",
        "    return tf_idf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document = example_sent\n",
        "corpus = [\n",
        "    \"After the thunderstorm\",\n",
        "    \"The mesmerizing rainbow appeared in the sky\",\n",
        "    \"Casting a colorful reflection on the rippling surface of the lake\",\n",
        "    \"The birds chirped and flew over the treetops\"\n",
        "]\n",
        "\n",
        "tf_idf = calculate_tf_idf(document, corpus)"
      ],
      "metadata": {
        "id": "PbQ4EEo9Fsl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf_idf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j3ixnAyHFEV",
        "outputId": "aa79c974-7db8-469c-f885-e7227b0a31d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'After': 0.046209812037329684, 'the': 0.0, 'thunderstorm,': 0.0, 'mesmerizing': 0.046209812037329684, 'rainbow': 0.046209812037329684, 'appeared': 0.046209812037329684, 'in': 0.023104906018664842, 'sky,': 0.0, 'casting': 0.0, 'a': 0.009589402415059362, 'colorful': 0.046209812037329684, 'reflection': 0.046209812037329684, 'on': 0.046209812037329684, 'rippling': 0.046209812037329684, 'surface': 0.046209812037329684, 'of': 0.046209812037329684, 'lake,': 0.0, 'as': 0.046209812037329684, 'birds': 0.046209812037329684, 'chirped': 0.046209812037329684, 'and': 0.046209812037329684, 'flew': 0.046209812037329684, 'over': 0.046209812037329684, 'treetops.': 0.0}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}